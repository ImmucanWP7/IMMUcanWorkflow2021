---
title: "Train random forrest classifier"
site: workflowr::wflow_site
output:
  workflowr::wflow_html:
    toc: true
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

In this script, we will train a random forest classifier.

# Read in data 

First, we will read in the SingleCellExperiment object and load all libraries.

```{r read-sce, message = FALSE}
library(caret)
library(scater)
library(tidyverse)
library(dittoSeq)
library(viridis)
library(doParallel)

sce <- readRDS("/Volumes/immucan_volume/processed_data/Panel_1/2022_WORKFLOW/IMC/Rout/sce.rds")
```

# Random Forrest Training

After quality control, we will now use a random forest classifier to classify the remaining cells in the dataset. 
First, we will split the dataset into labelled and unlabelled data.

```{r split-labelled}
lab_sce <- sce[,sce$cell_labels != "unlabelled"]
unlab_sce <- sce[,sce$cell_labels == "unlabelled"]
```

## Splitting across all samples

We will split the labelled data based on their cell-types.

### Train and validate the classifier

We will first split the labelled data into training and test (validation) data at a ratio of 75/25 train/test.

```{r split-data}
set.seed(1234)
trainIndex <- createDataPartition(factor(lab_sce$cell_labels), p = 0.75)
train_sce <- lab_sce[,trainIndex$Resample1]
test_sce <- lab_sce[,-trainIndex$Resample1]
```

Here, we will first use a 5-fold cross-validation by partitioning the data randomly across the full dataset.
We will also use parallel processing for time reasons.
For the `randomForrest` classifier, we need to tune the `mtry` parameter - the number of variables sampled for each split.
We will also add the indication as dummy variable.

```{r train-model, message = FALSE}
# Define seeds for parallel processing
# Per iteration, we evaluate 10 models while tuning mtry
set.seed(222)
seeds <- vector(mode = "list", length = 6)
for (i in 1:5) {
  seeds[[i]] <- sample(5000, 5)
}
seeds[[6]] <- sample(5000, 1)

fitControl <- trainControl(method = "cv",
                           number = 5,
                           seeds = seeds)

cl <- makePSOCKcluster(6, setup_strategy = "sequential")
registerDoParallel(cl)

# Add dummy variables
cur_mat <- t(assay(train_sce, "exprs")[!grepl("DNA|Histone", rownames(train_sce)),])

dummies <- dummyVars(sample_id ~ indication, data = colData(train_sce))
all_dummies <- predict(dummies, newdata = colData(train_sce))

cur_mat <- cbind(cur_mat, all_dummies)

set.seed(1234)
rffit <- train(x = cur_mat, 
               y = factor(train_sce$cell_labels),
               method = "rf", ntree = 1000,
               tuneLength = 5,
               trControl = fitControl)
stopCluster(cl)

rffit

saveRDS(rffit,file = "/Volumes/immucan_volume/processed_data/Panel_1/2022_WORKFLOW/IMC/Rout/rf_classifier.rds")
```

We will now have a look at the accuracy measures over iterations.
The only parameter that has been tuned is `mtry`.

```{r accuracy}
ggplot(rffit) + 
  geom_errorbar(data = rffit$results,
                aes(ymin = Accuracy - AccuracySD,
                    ymax = Accuracy + AccuracySD),
                width = 0.4)
```

We can also compute the confusion matrix:

```{r confusion-matrix}
confusionMatrix(rffit)
```

We will also look at the variable importance.

```{r variable-importance, fig.height = 15}
cur_varImp <- varImp(rffit)
plot(cur_varImp)
```

Finally, we will validate the model using the test data.

```{r model-testing}
# Add dummy variables
cur_mat <- t(assay(test_sce, "exprs")[!grepl("DNA|Histone", rownames(test_sce)),])

dummies <- dummyVars(sample_id ~ indication, data = colData(test_sce))
all_dummies <- predict(dummies, newdata = colData(test_sce))

cur_mat <- cbind(cur_mat, all_dummies)

cur_pred <- predict(rffit, 
                    newdata = cur_mat)

cm <- confusionMatrix(data = cur_pred, 
                      reference = factor(test_sce$cell_labels), 
                      mode = "everything")
cm

data.frame(cm$byClass) %>%
  mutate(class = sub("Class: ", "", rownames(cm$byClass))) %>%
  ggplot() + 
  geom_point(aes(1 - Specificity, Sensitivity, 
                 size = Detection.Rate,
                 fill = class),
             shape = 21) + 
  scale_fill_manual(values = metadata(sce)$colour_vectors$cell_type) + 
  theme_bw() + 
  ylab("Sensitivity (TPR)") +
  xlab("1 - Specificity (FPR)")
```

We will also observe the distribution of classification probabilities per image and class:

```{r prediciton-probability, fig.width = 15}
cur_pred <- predict(rffit, 
                    newdata = cur_mat, 
                    type = "prob")
cur_pred$truth <- factor(test_sce$cell_labels)

cur_pred %>%
  pivot_longer(cols = Bcell:Tumor) %>%
  ggplot() +
  geom_boxplot(aes(x = name, y = value, fill = name), outlier.size = 0.5) +
  facet_wrap(. ~ truth) + 
  scale_fill_manual(values = metadata(sce)$colour_vectors$cell_type) +
  theme(panel.background = element_blank(), 
        axis.text.x = element_text(angle = 45, hjust = 1))
```
